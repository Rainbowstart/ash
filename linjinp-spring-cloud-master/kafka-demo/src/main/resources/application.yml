#配置端口号
server:
  port: 8089

spring:
  application:
    #配置服务名
    name: kafka-demo
  # 默认激活 sit 分支
  profiles:
    active: sit

  # kafka 配置
  kafka:
    # 在发出请求时传递给服务器的 id 字符串（用户自定义）
    # 这个不起眼的参数可以让我们知道，kafka 的每次调用来自哪个应用
    client-id: kafka-demo
    # 连接 kafka 服务器，集群多个用逗号隔开
    bootstrap-servers: 118.25.215.105:9092
    # 生产者配置
    producer:
      # 写入失败时，重试次数。当leader节点失效，一个repli节点会替代成为leader节点，此时可能出现写入失败，
      # 当 retris 为 0 时，produce 不会重复。retirs 重发，此时 replica 节点完全成为 leader 节点，不会产生消息丢失。
      # 默认 0
      retries: 0
      # 每次批量发送消息的数量，produce积累到一定数据，一次发送
      # 加大批处理，能提高性能，提高吞吐量，但是会增大内存的消耗，减小相反
      # 默认 16384
      batch-size: 16384
      # 用来缓冲等待被发送到服务器的记录的总字节数
      # 缓存大小达到buffer.memory就发送数据
      # 默认 33554432
      buffer-memory: 33554432
      # 此配置是 Producer 在确认一个请求发送完成之前需要收到的反馈信息的数量。 这个参数是为了保证发送请求的可靠性。
      # 0：如果设置为0，则 producer 不会等待服务器的反馈。添加到缓存后就当发送了，后续服务器是否请求无法保证，重试也不会生效
      # 1：leader 节点会将记录写入本地日志，并且在所有 follower 节点反馈之前就先确认成功。 follower 节点复制数据完成之前产生错误，则这条记录会丢失。
      # all：意味着 leader 节点会等待所有同步中的副本确认之后再确认这条记录是否发送完成。只要至少有一个同步副本存在，记录就不会丢失。这种方式是对请求传递的最有效保证。acks=-1与acks=all是等效的。
      # 默认 1
      acks: all
      # 指定消息key和消息体的编解码方式
      # 默认都是 org.apache.kafka.common.serialization.StringSerializer
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    # 消费者配置
    consumer:
      # 组 ID，在kafka中，同一组中的consumer不会读取到同一个消息
      # 举个例子，容器部署高可用，即 1 个应用部署多个容器实例
      # 这时，这几个应用的组 ID 都是一样的，同一条数据就不会被消费多次
      group-id: kafka-demo-1
      # 消费者消费数据的偏移量
      # earliest：当各分区下有已提交的offset时，从提交的 offset 开始消费；无提交的offset时，从头开始消费
      # latest：当各分区下有已提交的offset时，从提交的 offset 开始消费；无提交的offset时，消费新产生的该分区下的数据
      # none：当各分区都存在已提交的offset时，从 offset 后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
      #
      # 这个看业务场景吧，偏移量没有，差不多意思就是数据丢了，不知道读到哪了，像是发送短信通知这种的，latest 就行
      # 但是像处理一些重要的业务数据，比如财务之类的，如果丢了只能重头算，主要看数据的价值把，这时候就要用 earliest
      # 默认 latest
      auto-offset-reset: latest
      # 自动提交 offset
      enable-auto-commit: true
      # 指定消息key和消息体的编解码方式
      # 默认都是 org.apache.kafka.common.serialization.StringDeserializer
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    admin:
      # 同上
      client-id: kafka-demo-admin


  #Druid 连接池通用配置
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      # 下面为连接池的补充设置，应用到上面所有数据源中
      # 初始化大小，最小，最大
      initial-size: 5
      min-idle: 5
      max-active: 20
      # 配置获取连接等待超时的时间
      max-wait: 60000
      # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
      time-between-eviction-runs-millis: 60000
      # 配置一个连接在池中最小生存的时间，单位是毫秒
      min-evictable-idle-time-millis: 300000
      validation-query: select count(1) from sys.objects Where type='U' And type_desc='USER_TABLE'
      test-while-idle: true
      test-on-borrow: false
      test-on-return: false
      # 打开PSCache，并且指定每个连接上PSCache的大小
      pool-prepared-statements: true
      #   配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
      max-pool-prepared-statement-per-connection-size: 20
      filters: stat # wall 若开启 wall，会把 if 中的 and 判断为注入进行拦截
      use-global-data-source-stat: true
      # 通过connectProperties属性来打开mergeSql功能；慢SQL记录
      connect-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
      # 配置监控服务器
#      stat-view-servlet:
#        login-username: admin
#        login-password: 123456
#        reset-enable: false
#        url-pattern: /druid/*
#        # 添加IP白名单
#        #allow:
#        # 添加IP黑名单，当白名单和黑名单重复时，黑名单优先级更高
#        #deny:
#      web-stat-filter:
#        # 添加过滤规则
#        url-pattern: /*
#        # 忽略过滤格式
#        exclusions: "*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*"

#配置xml映射
mybatis:
  mapper-locations: mapper/*/*.xml, classpath*:mapper/*.xml
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl

#Actuator配置开放所有端点
management:
  endpoints:
    web:
      exposure:
        include: "*"
  endpoint:
    health:
      show-details: always

#pageHelper 分页插件
pagehelper:
  helperDialect: mysql
  reasonable: true
  supportMethodsArguments: true
  pageSizeZero: true
  params: count=countSql

---
#本地/测试服配置
spring:
  profiles: sit
  datasource:
    # Atlas
#    url: jdbc:mysql://118.25.215.105:1234/test
    # Mycat
    url: jdbc:mysql://118.25.215.105:8066/mysql1
    username: root
    password: MydnLmKHotFzcbM3/jKN6j7j4MqgzxYsGv32wZ1QKSzdHWB44sOn6VGwbLqCs1YFVZM3v5kTcHpIQ18zKL6DOw==
    publicKey: MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAIyb6+/M6yqU7NwSf8bdlZP4K09ohHMCsJOhrwpywaFm9Qv0iFL1+9DNcoiiT4KD8cLXlgUkx0Py6/GNyi9jrCUCAwEAAQ==
    driver-class-name: com.mysql.jdbc.Driver
#  #Redis配置
#  redis:
#    host: xxxx #redis 地址
#    password: xxxx
#    port: 6379
#    sentinel:
#      master: mymaster
#      nodes: xxxx,xxxx #redis 多节点地址
#    lettuce:
#      pool:
#        min-idle: 0
#        max-idle: 8
#        max-wait: -1ms
#        max-active: 8
#      shutdown-timeout: 100ms

#eureka配置
eureka:
  client:
    service-url:
#      defaultZone: http://118.25.215.105:8001/eureka/,http://118.25.215.105:8002/eureka/,http://118.25.215.105:8003/eureka/  #eureka 集群地址
      defaultZone: http://eureka.didispace.com/eureka
    #间隔多少秒去服务端拉去注册信息
    registry-fetch-interval-seconds: 10
  instance:
    #发送心跳给server端频率
    lease-renewal-interval-in-seconds: 30
    #健康检查地址
    health-check-url-path: /actuator/health
    prefer-ip-address: true

---

#正式服配置
spring:
  profiles: prod
  datasource:
    # Atlas
#    url: jdbc:mysql://118.25.215.105:1234/test
    # Mycat
    url: jdbc:mysql://118.25.215.105:8066/mysql1
    username: root
    password: MydnLmKHotFzcbM3/jKN6j7j4MqgzxYsGv32wZ1QKSzdHWB44sOn6VGwbLqCs1YFVZM3v5kTcHpIQ18zKL6DOw==
    publicKey: MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAIyb6+/M6yqU7NwSf8bdlZP4K09ohHMCsJOhrwpywaFm9Qv0iFL1+9DNcoiiT4KD8cLXlgUkx0Py6/GNyi9jrCUCAwEAAQ==
    driver-class-name: com.mysql.jdbc.Driver
  #Redis配置
#  redis:
#    lettuce:
#      pool:
#        min-idle: 0
#        max-idle: 8
#        max-wait: -1ms
#        max-active: 8
#      shutdown-timeout: 100ms
#    cluster:
#      nodes: xxxx,xxxx #redis 多节点地址

#eureka配置
eureka:
  client:
    service-url:
#      defaultZone: http://118.25.215.105:8001/eureka/,http://118.25.215.105:8002/eureka/,http://118.25.215.105:8003/eureka/  #eureka 集群地址
      defaultZone: http://eureka.didispace.com/eureka
    #间隔多少秒去服务端拉去注册信息
    registry-fetch-interval-seconds: 10
  instance:
    #发送心跳给server端频率
    lease-renewal-interval-in-seconds: 30
    #健康检查地址
    health-check-url-path: /actuator/health
    prefer-ip-address: true